@article{FILIGHEDDU202412,
title = {Using staged tree models for health data: Investigating invasive fungal infections by aspergillus and other filamentous fungi},
journal = {Computational and Structural Biotechnology Journal},
volume = {24},
pages = {12-22},
year = {2024},
issn = {2001-0370},
doi = {https://doi.org/10.1016/j.csbj.2023.11.013},
url = {https://www.sciencedirect.com/science/article/pii/S2001037023004282},
author = {Maria Teresa Filigheddu and Manuele Leonelli and Gherardo Varando and Miguel Ángel Gómez-Bermejo and Sofía Ventura-Díaz and Luis Gorospe and Jesús Fortún},
keywords = {Diagnostic criteria, Invasive aspergillosis, Machine learning, Probabilistic graphical models, Staged trees},
abstract = {Machine learning models are increasingly used in the medical domain to study the association between risk factors and diseases to support practitioners in understanding health outcomes. In this paper, we showcase the use of machine-learned staged tree models for investigating complex asymmetric dependence structures in health data. Staged trees are a specific class of generative, probabilistic graphical models that formally model asymmetric conditional independence and non-regular sample spaces. An investigation of the risk factors in invasive fungal infections demonstrates the insights staged trees provide to support medical decision-making.}
}

@article{varando2024staged,
  title={Staged trees and asymmetry-labeled DAGs},
  author={Varando, Gherardo and Carli, Federico and Leonelli, Manuele},
  journal={Metrika},
  pages={1--28},
  year={2024},
  publisher={Springer},
  url={https://link.springer.com/article/10.1007/s00184-024-00957-1}
}

@article{leonelli2024structural,
  title={Structural learning of simple staged trees},
  author={Leonelli, Manuele and Varando, Gherardo},
  journal={Data Mining and Knowledge Discovery},
  pages={1--25},
  year={2024},
  publisher={Springer},
  url={https://link.springer.com/article/10.1007/s10618-024-01007-0}
}



@article{leonelli2024learning,
  title={Learning and interpreting asymmetry-labeled DAGs: a case study on COVID-19 fear},
  author={Leonelli, Manuele and Varando, Gherardo},
  journal={Applied Intelligence},
  volume={54},
  number={2},
  pages={1734--1750},
  year={2024},
  publisher={Springer},
  url={https://link.springer.com/article/10.1007/s10489-024-05268-6}
}


@inproceedings{
anonymous2024semiparametric,
title={Semiparametric Inference and Equation Discovery with the Bayesian Machine Scientist},
author={Anonymous},
booktitle={ICLR 2024 Workshop on AI4DifferentialEquations In Science},
year={2024},
url={https://openreview.net/forum?id=7YqV4deFAc}
}

@inproceedings{
cohrs2023large,
title={Large Language Models for Constrained-Based Causal Discovery},
author={Kai-Hendrik Cohrs and Emiliano Diaz and Vasileios Sitokonstantinou and Gherardo Varando and Gustau Camps-Valls},
booktitle={AAAI 2024 Workshop on ''Are Large Language Models Simply Causal Parrots?''},
year={2023},
url={https://openreview.net/forum?id=NEAoZRWHPN}
}

@article{CAMPSVALLS20231,
title = {Discovering causal relations and equations from data},
journal = {Physics Reports},
volume = {1044},
pages = {1-68},
year = {2023},
note = {Discovering causal relations and equations from data},
issn = {0370-1573},
doi = {https://doi.org/10.1016/j.physrep.2023.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S0370157323003411},
author = {Gustau Camps-Valls and Andreas Gerhardus and Urmi Ninad and Gherardo Varando and Georg Martius and Emili Balaguer-Ballester and Ricardo Vinuesa and Emiliano Diaz and Laure Zanna and Jakob Runge},
keywords = {Causal inference, Causal discovery, Complex systems, Nonlinear dynamics, Equation discovery, Knowledge discovery, Understanding, Artificial intelligence, Neuroscience, Climate science},
abstract = {Physics is a field of science that has traditionally used the scientific method to answer questions about why natural phenomena occur and to make testable models that explain the phenomena. Discovering equations, laws, and principles that are invariant, robust, and causal has been fundamental in physical sciences throughout the centuries. Discoveries emerge from observing the world and, when possible, performing interventions on the system under study. With the advent of big data and data-driven methods, the fields of causal and equation discovery have developed and accelerated progress in computer science, physics, statistics, philosophy, and many applied fields. This paper reviews the concepts, methods, and relevant works on causal and equation discovery in the broad field of physics and outlines the most important challenges and promising future lines of research. We also provide a taxonomy for data-driven causal and equation discovery, point out connections, and showcase comprehensive case studies in Earth and climate sciences, fluid dynamics and mechanics, and the neurosciences. This review demonstrates that discovering fundamental laws and causal relations by observing natural phenomena is revolutionised with the efficient exploitation of observational data and simulations, modern machine learning algorithms and the combination with domain knowledge. Exciting times are ahead with many challenges and opportunities to improve our understanding of complex systems.}
}

@article{varando2024pairwise,
title = {Pairwise causal discovery with support measure machines},
journal = {Applied Soft Computing},
volume = {150},
pages = {111030},
year = {2024},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2023.111030},
url = {https://www.sciencedirect.com/science/article/pii/S1568494623010487},
author = {Gherardo Varando and Salvador Catsis and Emiliano Diaz and Gustau Camps-Valls},
keywords = {Pairwise causal discovery, Kernel methods, Kernel mean embedding, Support vector machine, Ensemble methods},
abstract = {Bivariate causal discovery amounts to inferring the causal association between two random variables, usually from observational data. This task is the simplest and most fundamental causal discovery problem from which more complex discovery methods can be envisioned and developed. Classical bivariate causal discovery methods exploit a combination of specific sets of assumptions and data to obtain identifiability of the causal direction. Data-driven supervised approaches train machine learning models over large sets of causally-labeled bivariate datasets to learn the task of inferring the causal relationship from data. In this work, an ensemble algorithm based on support measure machines is proposed with the aim of combining the strength of different classical approaches (base methods) with data-driven decisions. In particular, support measure machine classifiers are trained to estimate the performance of each base method. Their decision functions are then used as data-dependent weights of a weighted voting scheme to estimate the causal direction in a bivariate causal discovery problem. This work demonstrates that the proposed algorithm, denoted as Causal Ensemble Measure Machine, performs equal to or better than state-of-the-art methods on a wide range of synthetic and real-world bivariate problems. Perhaps more importantly, this method enables a closer examination of the assumption dependence of existing algorithms on observational data.}
}

@article{runge2023causal,
  title={Causal inference for time series},
  author={Runge, Jakob and Gerhardus, Andreas and Varando, Gherardo and Eyring, Veronika and Camps-Valls, Gustau},
  journal={Nature Reviews Earth \& Environment},
  pages={1--19},
  year={2023},
  publisher={Nature Publishing Group UK London},
  doi = {https://doi.org/10.1038/s43017-023-00431-y}
}

@article{diaz2023learning,
	author={Díaz, Emiliano and Varando, Gherardo and Johnson, J. Emmanuel and Camps-Valls, Gustau},
	title={Learning latent functions for causal discovery},
	journal={Machine Learning: Science and Technology},
	url={http://iopscience.iop.org/article/10.1088/2632-2153/ace151},
	year={2023},
	abstract={Causal discovery from observational data offers unique opportunities in many scientific disciplines: reconstructing causal drivers, testing causal hypotheses, and comparing and evaluating models for optimizing targeted interventions. Recent causal discovery methods focused on estimating the latent space of the data to get around a lack of causal sufficiency or additivity constraints. However, estimating the latent space significantly increases model complexity, compromising causal identifiability and making it hard to compare models that correspond to different causal hypotheses. We propose a kernel, non-parametric latent-space modelling approach and deal with the difficulty of comparing causal directions by measuring and controlling for the level of causal assumption fulfilment. We introduce a latent noise causal inference framework to estimate latent factors associated with the hypothesized causal direction by optimizing a loss function with kernel independence criteria. We extend the framework to work with time series using an additional time-dependent kernel regularizer. We discuss the additivity assumption and model complexity and give empirical evidence of performance in a wide range of synthetic and real causal discovery problems.}
}

@InProceedings{pmlr-v206-leonelli23a,
  title = 	 {Context-Specific Causal Discovery for Categorical Data Using Staged Trees},
  author =       {Leonelli, Manuele and Varando, Gherardo},
  booktitle = 	 {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {8871--8888},
  year = 	 {2023},
  editor = 	 {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},
  volume = 	 {206},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {25--27 Apr},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v206/leonelli23a/leonelli23a.pdf},
  url = 	 {https://proceedings.mlr.press/v206/leonelli23a.html},
  abstract = 	 {Causal discovery algorithms aim at untangling complex causal relationships from data. Here, we study causal discovery and inference methods based on staged tree models, which can represent complex and asymmetric causal relationships between categorical variables. We provide a first graphical representation of the equivalence class of a staged tree, by looking only at a specific subset of its underlying independences. We further define a new pre-metric, inspired by the widely used structural intervention distance, to quantify the closeness between two staged trees in terms of their corresponding causal inference statements. A simulation study highlights the efficacy of staged trees in uncovering complexes, asymmetric causal relationships from data, and real-world data applications illustrate their use in practical causal analysis.}
}

@article{CARLI2023110488,
title = {A new class of generative classifiers based on staged tree models},
journal = {Knowledge-Based Systems},
pages = {110488},
year = {2023},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2023.110488},
url = {https://www.sciencedirect.com/science/article/pii/S0950705123002381},
author = {Federico Carli and Manuele Leonelli and Gherardo Varando},
keywords = {Bayesian networks, Model selection, Staged trees, Statistical classification},
abstract = {Generative models for classification use the joint probability distribution of the class variable and the features to construct a decision rule. Among generative models, Bayesian networks and naive Bayes classifiers are the most commonly used and provide a clear graphical representation of the relationship among all variables. However, these have the disadvantage of highly restricting the type of relationships that could exist, by not allowing for context-specific independence. Here we introduce a new class of generative classifiers, called staged tree classifiers, which formally account for context-specific independence. They are constructed by a partitioning of the vertices of an event tree from which conditional independence can be formally read. The naive staged tree classifier is also defined, which extends the classic naive Bayes classifier whilst retaining the same complexity. An extensive simulation study shows that the classification accuracy of staged tree classifiers is competitive with that of state-of-the-art classifiers and an example showcases their use in practice.}
}

@InProceedings{pmlr-v186-leonelli22a,
  title = 	 {Highly Efficient Structural Learning of Sparse Staged Trees},
  author =       {Leonelli, Manuele and Varando, Gherardo},
  booktitle = 	 {Proceedings of The 11th International Conference on Probabilistic Graphical Models},
  pages = 	 {193--204},
  year = 	 {2022},
  editor = 	 {Salmerón, Antonio and Rumí, Rafael},
  volume = 	 {186},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {05--07 Oct},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v186/leonelli22a/leonelli22a.pdf},
  url = 	 {https://proceedings.mlr.press/v186/leonelli22a.html},
  abstract = 	 {Several structural learning algorithms for staged tree models, an asymmetric extension of Bayesian networks, have been defined. However, they do not scale efficiently as the number of variables considered increases. Here we introduce the first scalable structural learning algorithm for staged trees, which searches over a space of models where only a small number of dependencies can be imposed. A simulation study as well as a real-world application illustrate our routines and the practical use of such data-learned staged trees.}
}




@article{JSSv102i06,
 title={The {R} Package stagedtrees for Structural Learning of Stratified Staged Trees},
 volume={102},
 url={https://www.jstatsoft.org/index.php/jss/article/view/v102i06},
 doi={10.18637/jss.v102.i06},
 number={6},
 journal={Journal of Statistical Software},
 author={Carli, Federico and Leonelli, Manuele and Riccomagno, Eva and Varando, Gherardo},
 year={2022},
 pages={1–30}
}



@article{DBLP:journals/access/CordobaBLV20,
  author    = {Irene C{\'{o}}rdoba and
               Concha Bielza and
               Pedro Larra{\~{n}}aga and
               Gherardo Varando},
  title     = {Sparse {C}holesky Covariance Parametrization for Recovering Latent Structure
               in Ordered Data},
  journal   = {{IEEE} Access},
  volume    = {8},
  pages     = {154614--154624},
  year      = {2020},
  doi       = {10.1109/ACCESS.2020.3018593},
  timestamp = {Mon, 03 Jan 2022 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/journals/access/CordobaBLV20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/ijar/CordobaVBL20,
  author    = {Irene C{\'{o}}rdoba and
               Gherardo Varando and
               Concha Bielza and
               Pedro Larra{\~{n}}aga},
  title     = {On generating random {G}aussian graphical models},
  journal   = {Int. J. Approx. Reason.},
  volume    = {125},
  pages     = {240--250},
  year      = {2020},
  doi       = {10.1016/j.ijar.2020.07.007},
  timestamp = {Mon, 03 Jan 2022 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/journals/ijar/CordobaVBL20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{pmlr-v124-varando20a,
  title = 	 {Graphical continuous {L}yapunov models},
  author =       {Varando, Gherardo and Richard Hansen, Niels},
  booktitle = 	 {Proceedings of the 36th Conference on Uncertainty in Artificial Intelligence (UAI)},
  pages = 	 {989--998},
  year = 	 {2020},
  editor = 	 {Peters, Jonas and Sontag, David},
  volume = 	 {124},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {03--06 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v124/varando20a/varando20a.pdf},
  url = 	 {https://proceedings.mlr.press/v124/varando20a.html},
  abstract = 	 {The linear Lyapunov equation of a covariance matrix parametrizes theequilibrium covariance matrix of a stochastic process. This parametrization canbe interpreted as a new graphical model class, and we show how the model classbehaves under marginalization and introduce a method for structure learning via$\ell_1$-penalized loss minimization. Our proposed method is demonstrated tooutperform alternative structure learning algorithms in a simulation study, andwe illustrate its application for protein phosphorylation network reconstruction.}
}

@misc{varando2020learning,
      title={Learning {DAG}s without imposing acyclicity}, 
      author={Gherardo Varando},
      year={2020},
      eprint={2006.03005},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}


@InProceedings{pmlr-v123-weichwald20a,
  title = 	 {Causal structure learning from time series: {L}arge regression coefficients may predict causal links better in practice than small p-values},
  author =       {Weichwald, Sebastian and Jakobsen, Martin E. and Mogensen, Phillip B. and Petersen, Lasse and Thams, Nikolaj and Varando, Gherardo},
  booktitle = 	 {Proceedings of the NeurIPS 2019 Competition and Demonstration Track},
  pages = 	 {27--36},
  year = 	 {2020},
  editor = 	 {Escalante, Hugo Jair and Hadsell, Raia},
  volume = 	 {123},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {08--14 Dec},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v123/weichwald20a/weichwald20a.pdf},
  url = 	 {https://proceedings.mlr.press/v123/weichwald20a.html},
  abstract = 	 {In this article, we describe the algorithms for causal structure learning from time series data that won the Causality 4 Climate competition at the Conference on Neural Information Processing Systems 2019 (NeurIPS). We examine how our combination of established ideas achieves competitive performance on semi-realistic and realistic time series data exhibiting common challenges in real-world Earth sciences data. In particular, we discuss a) a rationale for leveraging linear methods to identify causal links in non-linear systems, b) a simulation-backed explanation as to why large regression coefficients may predict causal links better in practice than small p-values and thus why normalising the data may sometimes hinder causal structure learning. For benchmark usage, we detail the algorithms here and provide implementations at {https://github.com/sweichwald/tidybench}. We propose the presented competition-proven methods for baseline benchmark comparisons to guide the development of novel algorithms for structure learning from time series.}
}


@inproceedings{DBLP:conf/ideal/CordobaVBL18,
  author    = {Irene C{\'{o}}rdoba and
               Gherardo Varando and
               Concha Bielza and
               Pedro Larra{\~{n}}aga},
  editor    = {Hujun Yin and
               David Camacho and
               Paulo Novais and
               Antonio J. Tall{\'{o}}n{-}Ballesteros},
  title     = {A Fast {M}etropolis-{H}astings Method for Generating Random Correlation
               Matrices},
  booktitle = {Intelligent Data Engineering and Automated Learning - {IDEAL} 2018
               - 19th International Conference, Madrid, Spain, November 21-23, 2018,
               Proceedings, Part {I}},
  series    = {Lecture Notes in Computer Science},
  volume    = {11314},
  pages     = {117--124},
  publisher = {Springer},
  year      = {2018},
  doi       = {10.1007/978-3-030-03493-1\_13},
  timestamp = {Tue, 14 May 2019 10:00:45 +0200},
  biburl    = {https://dblp.org/rec/conf/ideal/CordobaVBL18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/pgm/CordobaVBL18,
  author    = {Irene C{\'{o}}rdoba and
               Gherardo Varando and
               Concha Bielza and
               Pedro Larra{\~{n}}aga},
  editor    = {Milan Studen{\'{y}} and
               V{\'{a}}clav Kratochv{\'{\i}}l},
  title     = {A partial orthogonalization method for simulating covariance and concentration
               graph matrices},
  booktitle = {International Conference on Probabilistic Graphical Models, {PGM}
               2018, 11-14 September 2018, Prague, Czech Republic},
  series    = {Proceedings of Machine Learning Research},
  volume    = {72},
  pages     = {61--72},
  publisher = {{PMLR}},
  year      = {2018},
  url       = {http://proceedings.mlr.press/v72/cordoba18a.html},
  timestamp = {Wed, 03 Apr 2019 18:17:22 +0200},
  biburl    = {https://dblp.org/rec/conf/pgm/CordobaVBL18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{varando2018markov,
      title={{M}arkov Property in Generative Classifiers}, 
      author={Gherardo Varando and Concha Bielza and Pedro Larrañaga and Eva Riccomagno},
      year={2018},
      eprint={1811.04759},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@ARTICLE{10.3389/fnana.2018.00037,
AUTHOR={Varando, Gherardo and Benavides-Piccione, Ruth and Muñoz, Alberto and Kastanauskaite, Asta and Bielza, Concha and Larrañaga, Pedro and DeFelipe, Javier},
TITLE={Multi{M}ap: A Tool to Automatically Extract and Analyse Spatial Microscopic Data From Large Stacks of Confocal Microscopy Images},
JOURNAL={Frontiers in Neuroanatomy},
VOLUME={12},
YEAR={2018},
URL={https://www.frontiersin.org/article/10.3389/fnana.2018.00037},
DOI={10.3389/fnana.2018.00037},
ISSN={1662-5129}
}

@article{DBLP:journals/ijar/VarandoBL16,
  author    = {Gherardo Varando and
               Concha Bielza and
               Pedro Larra{\~{n}}aga},
  title     = {Decision functions for chain classifiers based on {B}ayesian networks
               for multi-label classification},
  journal   = {Int. J. Approx. Reason.},
  volume    = {68},
  pages     = {164--178},
  year      = {2016},
  doi       = {10.1016/j.ijar.2015.06.006},
  timestamp = {Tue, 16 Feb 2021 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/journals/ijar/VarandoBL16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/ijis/VarandoLNLB15,
  author    = {Gherardo Varando and
               Pedro L. L{\'{o}}pez{-}Cruz and
               Thomas D. Nielsen and
               Pedro Larra{\~{n}}aga and
               Concha Bielza},
  title     = {Conditional Density Approximations with Mixtures of Polynomials},
  journal   = {Int. J. Intell. Syst.},
  volume    = {30},
  number    = {3},
  pages     = {236--264},
  year      = {2015},
  doi       = {10.1002/int.21699},
  timestamp = {Mon, 26 Oct 2020 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/journals/ijis/VarandoLNLB15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/jmlr/VarandoBL15,
  author    = {Gherardo Varando and
               Concha Bielza and
               Pedro Larra{\~{n}}aga},
  title     = {Decision boundary for discrete {B}ayesian network classifiers},
  journal   = {J. Mach. Learn. Res.},
  volume    = {16},
  pages     = {2725--2749},
  year      = {2015},
  url       = {http://dl.acm.org/citation.cfm?id=2912086},
  timestamp = {Wed, 10 Jul 2019 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/jmlr/VarandoBL15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/widm/BorchaniVBL15,
  author    = {Hanen Borchani and
               Gherardo Varando and
               Concha Bielza and
               Pedro Larra{\~{n}}aga},
  title     = {A survey on multi-output regression},
  journal   = {WIREs Data Mining Knowl. Discov.},
  volume    = {5},
  number    = {5},
  pages     = {216--233},
  year      = {2015},
  doi       = {10.1002/widm.1157},
  timestamp = {Fri, 21 Jan 2022 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/journals/widm/BorchaniVBL15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/pgm/VarandoBL14,
  author    = {Gherardo Varando and
               Concha Bielza and
               Pedro Larra{\~{n}}aga},
  editor    = {Linda C. van der Gaag and
               A. J. Feelders},
  title     = {Expressive Power of Binary Relevance and Chain Classifiers Based on
	  {B}ayesian Networks for Multi-label Classification},
  booktitle = {Probabilistic Graphical Models - 7th European Workshop, {PGM} 2014,
               Utrecht, The Netherlands, September 17-19, 2014. Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {8754},
  pages     = {519--534},
  publisher = {Springer},
  year      = {2014},
  doi       = {10.1007/978-3-319-11433-0\_34},
  timestamp = {Sat, 19 Oct 2019 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/pgm/VarandoBL14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


